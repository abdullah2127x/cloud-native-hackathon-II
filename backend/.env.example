# Backend Environment Configuration
# Copy this file to .env and update with your actual values

# Database Configuration
# PostgreSQL connection string
# Format: postgresql://username:password@host:port/database
#
# Example with Neon Serverless:
# DATABASE_URL=postgresql://user:password@ep-example-123456.us-east-2.aws.neon.tech/neondb?sslmode=require
#
# NOTE: If the server freezes on startup, try removing channel_binding=require from the URL
# Working Neon connection (without channel_binding):
# DATABASE_URL=postgresql://user:password@ep-example-123456-pooler.us-east-1.aws.neon.tech/neondb?sslmode=require
#
# For local PostgreSQL:
DATABASE_URL=postgresql://user:password@localhost:5432/todo_app

# Better Auth Configuration
# URL where your Next.js frontend is running (for JWKS verification)
BETTER_AUTH_URL=http://localhost:3000

# CORS Configuration
# Allowed origins for Cross-Origin Resource Sharing
# Must be a JSON array of strings
CORS_ORIGINS=["http://localhost:3000"]

# Application Configuration (Optional)
# APP_NAME=Todo Backend API
# DEBUG=false
# JWT_ALGORITHM=EdDSA

# Phase 3+ Features (Optional, for future phases)
# NOTIFICATION_SERVICE_URL=http://localhost:9000
# NOTIFICATION_SERVICE_KEY=your-notification-key
# STORAGE_BUCKET_NAME=your-bucket
# ANALYTICS_KEY=your-analytics-key
# REDIS_URL=redis://localhost:6379  # For caching/sessions

# LLM Configuration (for OpenAI Agents SDK)
# Get free OpenRouter API key from https://openrouter.ai
# OPENROUTER_API_KEY=sk-or-...

# Alternative: Use OpenAI API
# OPENAI_API_KEY=sk-proj-...

# Alternative: Use Google Gemini
# GEMINI_API_KEY=your-gemini-key

# LLM Provider Selection (options: openrouter, openai, gemini)
# LLM_PROVIDER=openrouter

# LLM Model (for OpenRouter: openai/gpt-4o-mini, meta-llama/llama-3.2-3b-instruct:free, etc.)
# LLM_MODEL=openai/gpt-4o-mini
